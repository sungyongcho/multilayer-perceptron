def train_neural_network(
    model, X_train, y_train, X_valid, y_valid, epochs=10, batch_size=None
):
    (
        train_loss_history,
        train_accuracy_history,
        valid_loss_history,
        valid_accuracy_history,
    ) = ([], [], [], [])

    train_steps = len(X_train) // batch_size if batch_size else 1
    validation_steps = len(X_valid) // batch_size if batch_size else 1

    for epoch in range(epochs):
        print(f"Epoch: {epoch + 1}")
        train_loss, train_accuracy = self.process_data(
            X_train, y_train, train_steps, batch_size, is_training=True
        )
        train_loss_history.append(train_loss)
        train_accuracy_history.append(train_accuracy)

        if X_valid is not None and y_valid is not None:
            valid_loss, valid_accuracy = self.process_data(
                X_valid, y_valid, validation_steps, batch_size, is_training=False
            )
            valid_loss_history.append(valid_loss)
            valid_accuracy_history.append(valid_accuracy)
            print(f"Validation - Accuracy: {valid_accuracy}, Loss: {valid_loss}")

        print(f"Training - Accuracy: {train_accuracy}, Loss: {train_loss}")


def process_data(self, X, y, steps, batch_size, is_training=True):
    total_loss, total_accuracy, total_samples = 0, 0, 0

    for step in range(steps):
        batch_X, batch_y = get_batch(X, y, step, batch_size)

        y_pred = self.feedforward(batch_X)
        batch_cross_entropy = crossentropy(batch_y, y_pred)
        loss = np.mean(batch_cross_entropy)

        total_loss += np.sum(batch_cross_entropy)
        total_samples += len(batch_cross_entropy)

        batch_compare = self.accuracy(batch_y, y_pred)
        accuracy = np.mean(batch_compare)
        total_accuracy += np.sum(batch_compare)

        if is_training and (not step % 100 or step == steps - 1):
            print(f"Step: {step}, Accuracy: {accuracy}, Loss: {loss}")

        self.backpropagation(batch_y, y_pred, loss)

    epoch_loss = total_loss / total_samples
    epoch_accuracy = total_accuracy / total_samples

    return epoch_loss, epoch_accuracy


def get_batch(self, X, y, step, batch_size):
    if batch_size is None:
        return X, y
    else:
        start_idx = step * batch_size
        end_idx = (step + 1) * batch_size
        return X[start_idx:end_idx], y[start_idx:end_idx]
